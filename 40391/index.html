<html>
    
    <head>
        <link rel="stylesheet" href="../luca.css" type="text/css">
            
            <title>Fall 2019 | 40391 Topics in computer science and optimization </title>
            
            
    </head>
    
    <body><center>
        <h1>Fall 2019 &mdash; 40391 Topics in computer science and optimization</h1>
        </center>
    
        This course is an introduction to algorithms for combinatorial optimization problems and for convex optimization problems. Topics will include greedy and dynamic programming approaches to network optimization problems, cut, flow and matching algorithms,  linear programming, gradient descent, mirror descent, and Follow-the-Regularized-Leader algorithm for online convex optimization.
    
    
    <hr>
    
    <h3>General information</h3>
    
    Instructor: <a href=https://lucatrevisan.github.io>Luca Trevisan</a>
    
    <p>
    
    Lectures:
    <ul>
        <li>Tuesdays and Wednesdays 16:15-17:45</li>
    </ul>
    
    <p>
    
    Office hours: Thursdays 11-noon in 3-E1-14 Roentgen (from Sept 12 to Dec 5)
    
    <p>
    
    References:
    <ul>
        <li>A good reference for optimization techniques in discrete algorithms (greedy, dynamic programming, iterated improvements) and a general introduction to graphs and graph algorithms is
            <ul>
                <li>S. Dasgupta, C.H. Papadimitriou, and U.V. Vazirani. Algorithms</li></ul>
            </li>
        
        <li>Dasgupta et al. is also a good reference for max flow, min cut, and linear programming. Additional material on such topics, including online optimization, is in
            <ul>
                <li><a href=https://lucatrevisan.github.io/books/cs261.pdf>My note for Stanford CS261</a></li></ul>
        </li>
        <li>I will write additional notes on online convex optimization and FTRL algorithms.</li>
    
    </ul>
    
    Exam: the exam will be a take-home final
    
    <hr>

    <h3>Past lectures</h3>
    
    <ol>
        <li> 9/11. Overview of the course. Greedy methodology. Minimum spanning tree. (Reference: Dasgupta section 5.1)
            </li>
        </ol>
    
    <hr>
    
    <h3>Plan for the course</h3>
    
    <ul>
        <li>Lectures 1-2: introduction, greedy algorithms, dynamic programming
            </li>
        <li> Lectures 3-5: iterative-improvement algorithms, max flow, min cut, matching
            </li>
        <li> Lectures 6-9: linear programming, simplex and duality, application to compressed sensing, application to 2-player 0-sum games</li>
        <li> Lectures 10-12: online convex optimization, multiplicative weights, solving 2-player 0-sum games, FTRL, recovering multiplicative weights and gradient descent as special cases of FTRL, Bregman projection</li>
        </ul>
    
    </body>
    
    
    
</html>
