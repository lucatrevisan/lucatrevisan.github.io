<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="GENERATOR" content="Microsoft FrontPage 4.0">
   <title>Luca Trevisan | Computational Complexity</title>
   
   <style>
body{margin:10px 10px 10px 10px;font-family:sans-serif;background-color:#FFFFFb;}
a{text-decoration:none}
a:link{color:#4444aa;}
a:visited{color:#4444aa;}
a:hover{background-color:#aaaaFF;}
li{line-height : 130%;}
</style>
</head>
<body>

<h1>
Projects</h1>
<hr WIDTH="100%">
<h3>Important Dates </h3>
<p>Project <b>proposals</b> are due by April 29 </p>
<p>Project reports are due by May 14 </p>
<hr>
<h3>Content of the projects </h3>
<p>A project can either be a <i>study</i> project or a <i>research</i> project. </p>
<p>In a study project you focus on an important result, or set of results, that
is not covered in detail in the course. Your proposal references the paper or
set of papers that you will study, and a goal. Usually the goal will be to
completely understand an important technical result, and to fill in the details of
an important technical lemma that is only stated without proof (or with a
sketchy proof) in the literature, or observe a simplified argument for a
technical proof, or something along these lines. Your report will describe the
big picture (the problem you are interested in, and the known results) and a
report of what you achieved towards your goal. (A detailed exposition of a
technical result, a simplified proof, etc.)</p>
<p>A <i> research</i> project starts with a general goal, like &quot;improve the
inapproximability result for Metric TSP,&quot; or &quot;Prove P=/=NP.&quot;
Towards this goal, you read the relevant papers, try various approaches, and
then you may or may not reach your goal. At the end you write a report detailing
your efforts. Obviously, regardless of the chosen problem, the chances of making
interesting progress are not good. In the ideal case, one would come with a
promising idea, show how it solves a non-trivial special case as a proof of
concept, and then have something to think about during the summer. If no
progress is made, any research project can become a study one.</p>
<h3>Collaboration</h3>
<p>Every student submitting a study project should submit an individual report.
A group of two or three students can work together provided they find a way to
study a broad question, and to divide up the work they plan to include in their
individual reports.</p>
<p>A research project can be assigned to a team of two.</p>
<hr>
<h1>Examples</h1>
<p>Any important result in complexity can be the base for a study project, and
any interesting open question can the base for a research project.</p>
<p>Here are some examples of study projects. Ask me for the references.</p>
<ul>
  <li><b>Conditional derandomization</b>.<br>
    Study some subset of the following papers:&nbsp; Nisan-Wigderson (basic
    trade-off between average-case complexity and derandomization),
    Impagliazzo-Wigderson (worst-case to average-case equivalence)
    Sudan-Trevisan-Vadhan (&quot;simplified&quot; proof of Impagliazzo-Wigderson)
    Shaltiel-Umans (algebraic construction of pseudorandom generators),</li>
  <li><b>Unconditional Derandomization&nbsp;</b>
    <ul>
      <li>Derandomization of polynomial identity testing for polynomials
        computed by &quot;non-commutative branching programs&quot;<br>
        See the paper of Shpilka and Raz <a href="http://www.wisdom.weizmann.ac.il/~ranraz/publications/indexDR.html">[here]
        </a></li>
      <li>Derandomization of low degree polynomials: work of Bogdanov-Viola,
        Lovett, Viola [<a href="http://lucatrevisan.wordpress.com/2008/01/11/pseudorandomness-for-polynomials/">see
        here</a>]</li>
      <li>Towards derandomization of RL: work of Reingold-Trevisan-Vadhan and
        Rozenman-Vadhan</li>
    </ul>
  </li>
  <li><b>Average-case complexity in NP</b>
    <ul>
      <li>Impossibility results for worst-case to average-case equivalence for
        NP-complete problems (Feigenbaum-Fortnow, Bogdanov-Trevisan, Viola)</li>
      <li>Amplification of average-case hardness of problems in NP (O'Donnell, .
        . . )</li>
    </ul>
  </li>
  <li><b>Average-case complexity of lattice problems</b>
    <ul>
      <li>Existence of lattice problems that are as hard on average as on worst
        case (Ajtai, Regev, ...)</li>
      <li>Existence of public key cryptosystems of security equivalent to the
        worst case complexity of a lattice problem (Ajtai-Dwork, Regev...)</li>
    </ul>
  </li>
  <li><b>Inapproximability results </b>based on the &quot;unique games
    conjecture&quot;
    <ul>
      <li>Hardness of Vertex Cover within 2 and of k-uniform Hypergraph Vertex
        Cover within k</li>
      <li>Hardness of Max CUT within .878... (with additional assumptions)</li>
    </ul>
  </li>
  <li><b>Proof complexity</b>
    <ul>
      <li>Lower bounds on datalog programs to refute random instances of 3SAT</li>
    </ul>
  </li>
  <li>Lower bounds for <b>monotone circuits</b>
    <ul>
      <li>Razborov's lower bound for clique</li>
      <li>The depth lower bound for st-connectivity</li>
    </ul>
  </li>
  <li>Lower bounds in <b>communication complexity</b>
    <ul>
      <li>The Babai-Nisan-Szegedy &quot;number on the forehead&quot; model</li>
    </ul>
  </li>
  <li>Lower bounds for <b>algebraic circuits</b>
    <ul>
      <li>Nisan's lower bound for non-commutative computations</li>
      <li>Raz's lower bound for multilinear formulas</li>
      <li>Impagliazzo-Kabanets connection between algebraic complexity and
        derandomization of polynomial identity testing</li>
    </ul>
  </li>
</ul>
<p>Some<a href="researchproj"> examples of research</a> projects [accessible
only from within berkeley.edu]</p>


</body>
</html>
